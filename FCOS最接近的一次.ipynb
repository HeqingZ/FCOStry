{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FCOSÊúÄÊé•ËøëÁöÑ‰∏ÄÊ¨°.ipynb",
      "provenance": [],
      "background_execution": "on",
      "authorship_tag": "ABX9TyM8AXycFpVxVWTSGtSH2TAR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HeqingZ/FCOStry/blob/main/FCOS%E6%9C%80%E6%8E%A5%E8%BF%91%E7%9A%84%E4%B8%80%E6%AC%A1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ew6ycvRMSkat",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b05f4dcc-ff6e-4e6f-9f2a-23d460a6dea3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#mount on google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#install detectron2\n",
        "!python -m pip install pyyaml==5.1\n",
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAb4BgfMSzR4",
        "outputId": "028778d6-6571-4073-caa5-e150a0e0268a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyyaml==5.1\n",
            "  Using cached PyYAML-5.1-cp37-cp37m-linux_x86_64.whl\n",
            "Installing collected packages: pyyaml\n",
            "Successfully installed pyyaml-5.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-4m9g4v0a\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-4m9g4v0a\n",
            "  Resolved https://github.com/facebookresearch/detectron2.git to commit 717ab9f0aeca216a2f800e43d705766251ba3a55\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m√ó\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m‚îÇ\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m√ó\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import some important utilities of Detectron2\n",
        "import torch, detectron2\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9kR4sS-S3vm",
        "outputId": "ec36d399-79bb-451f-805f-450bd11d4730"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n",
            "torch:  1.12 ; cuda:  cu113\n",
            "detectron2: 0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "#import features for the bbox\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from detectron2.structures import BoxMode"
      ],
      "metadata": {
        "id": "1HK0W8Q5TeEd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from ast import literal_eval\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "from detectron2.data import (DatasetCatalog, \n",
        "                             MetadataCatalog, \n",
        "                             build_detection_test_loader\n",
        "                            )\n",
        "from detectron2.data.datasets.coco import convert_to_coco_json\n",
        "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
        "from detectron2.structures import BoxMode\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.logger import setup_logger\n",
        "from detectron2.engine import DefaultTrainer, default_setup, hooks\n",
        "from detectron2.modeling import GeneralizedRCNNWithTTA\n",
        "from detectron2.evaluation import COCOEvaluator, DatasetEvaluators, inference_on_dataset\n",
        " \n",
        "\n",
        "logger = setup_logger()"
      ],
      "metadata": {
        "id": "plFlEmPkTe4F"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ],
      "metadata": {
        "id": "bVgxgv0FT38m",
        "outputId": "9fc8f136-e098-4455-a7b1-3b7358711455",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m‚ú®üç∞‚ú® Everything looks OK!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda --version"
      ],
      "metadata": {
        "id": "X1OSPHddT68i",
        "outputId": "5cae0035-495e-4f77-b03f-912e15a493ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conda 4.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fully install fcos\n",
        "!conda create --name FCOS\n",
        "!conda activate FCOS"
      ],
      "metadata": {
        "id": "KWMHxMEtThH-",
        "outputId": "5c5bb3b8-ba69-4898-a78c-927e3cbdc456",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\bdone\n",
            "Solving environment: / \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/FCOS\n",
            "\n",
            "\n",
            "\n",
            "Preparing transaction: \\ \b\bdone\n",
            "Verifying transaction: / \b\bdone\n",
            "Executing transaction: \\ \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate FCOS\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n",
            "Retrieving notices: ...working... done\n",
            "\n",
            "CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\n",
            "To initialize your shell, run\n",
            "\n",
            "    $ conda init <SHELL_NAME>\n",
            "\n",
            "Currently supported shells are:\n",
            "  - bash\n",
            "  - fish\n",
            "  - tcsh\n",
            "  - xonsh\n",
            "  - zsh\n",
            "  - powershell\n",
            "\n",
            "See 'conda init --help' for more information and options.\n",
            "\n",
            "IMPORTANT: You may need to close and restart your shell after running 'conda init'.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we give the instructions for CUDA 9.0\n",
        "!conda install -c pytorch torchvision=0.2.1 cudatoolkit=9.0\n"
      ],
      "metadata": {
        "id": "D3E3cwf6j654",
        "outputId": "25a0b41a-7bae-48ef-ba6b-277bb634d539",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\bfailed with initial frozen solve. Retrying with flexible solve.\n",
            "Collecting package metadata (repodata.json): | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\bfailed with initial frozen solve. Retrying with flexible solve.\n",
            "\n",
            "PackagesNotFoundError: The following packages are not available from current channels:\n",
            "\n",
            "  - cudatoolkit=9.0\n",
            "\n",
            "Current channels:\n",
            "\n",
            "  - https://conda.anaconda.org/pytorch/linux-64\n",
            "  - https://conda.anaconda.org/pytorch/noarch\n",
            "  - https://conda.anaconda.org/conda-forge/linux-64\n",
            "  - https://conda.anaconda.org/conda-forge/noarch\n",
            "\n",
            "To search for alternate channels that may provide the conda package you're\n",
            "looking for, navigate to\n",
            "\n",
            "    https://anaconda.org\n",
            "\n",
            "and use the search bar at the top of the page.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export INSTALL_DIR=$PWD\n"
      ],
      "metadata": {
        "id": "6hWjcVttkAxb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install pycocotools. Please make sure you have installed cython.\n",
        "%cd $INSTALL_DIR\n",
        "!git clone https://github.com/cocodataset/cocoapi.git\n",
        "%cd cocoapi/PythonAPI\n",
        "!python setup.py build_ext install\n",
        "\n"
      ],
      "metadata": {
        "id": "1F8eJ2f2qRfc",
        "outputId": "6646c26b-6454-4413-dd3a-50b765602874",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '$INSTALL_DIR'\n",
            "/content\n",
            "Cloning into 'cocoapi'...\n",
            "remote: Enumerating objects: 975, done.\u001b[K\n",
            "remote: Total 975 (delta 0), reused 0 (delta 0), pack-reused 975\u001b[K\n",
            "Receiving objects: 100% (975/975), 11.72 MiB | 13.31 MiB/s, done.\n",
            "Resolving deltas: 100% (576/576), done.\n",
            "/content/cocoapi/PythonAPI\n",
            "Traceback (most recent call last):\n",
            "  File \"setup.py\", line 2, in <module>\n",
            "    import numpy as np\n",
            "ModuleNotFoundError: No module named 'numpy'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install PyTorch Detection\n",
        "%cd $INSTALL_DIR\n",
        "!git clone https://github.com/tianzhi0549/FCOS.git\n",
        "%cd FCOS\n",
        "\n"
      ],
      "metadata": {
        "id": "a3JgD4pOqTFq",
        "outputId": "0bb6f8df-9db4-4d07-f963-2cb1114ffc92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '$INSTALL_DIR'\n",
            "/content/cocoapi/PythonAPI\n",
            "Cloning into 'FCOS'...\n",
            "remote: Enumerating objects: 2102, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 2102 (delta 6), reused 10 (delta 5), pack-reused 2090\u001b[K\n",
            "Receiving objects: 100% (2102/2102), 8.81 MiB | 11.77 MiB/s, done.\n",
            "Resolving deltas: 100% (1370/1370), done.\n",
            "/content/cocoapi/PythonAPI/FCOS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "zzGmKCva1Ebb"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the following will install the lib with\n",
        "# symbolic links, so that you can modify\n",
        "# the files if you want and won't need to\n",
        "# re-build it\n",
        "!python setup.py build develop --no-deps\n",
        "\n",
        "\n",
        "!unset INSTALL_DIR\n"
      ],
      "metadata": {
        "id": "XtNM0064qfa-",
        "outputId": "ad376329-39f7-4c6b-8434-68ca4124786d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"setup.py\", line 7, in <module>\n",
            "    import torch\n",
            "ModuleNotFoundError: No module named 'torch'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MjtmzDN-j6uF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#define the file path to retrieve images\n",
        "def FLIR(source_path, img_dir, anno_dir ): #define a function. assuming user doesnt know shit about coding and enter random stuff. related to anno dir and img dir\n",
        "    img_dir = os.path.join(source_path, img_dir)\n",
        "    anno_dir = os.path.join(source_path, anno_dir)\n",
        "    data_dicts = []\n",
        "    #define annotation properties\n",
        "    with open(anno_dir) as F:\n",
        "      jsonfile = json.load(F) #load annotations from json file into the dictionary\n",
        "    \n",
        "    annotationinfo = jsonfile[\"annotations\"]\n",
        "    imagesinfo = jsonfile[\"images\"] #retreieve info like category ID and bbox\n",
        "   \n",
        "    #define img sources\n",
        "     \n",
        "    img_dir_list = os.listdir(img_dir)#get the list of all files and directories in the specified directory.\n",
        "    # print(img_dir)\n",
        "    for img_info in imagesinfo: #bbox info category id\n",
        "      for images in img_dir_list:  #img_dir_list = img_dir, which is source_path/img_dir(original)\n",
        "        images = \"data/\" + images\n",
        "        if images == img_info['file_name']: #see if name matches each other, because we wanna find the filenames only for the small flir out of the whole json file\n",
        "\n",
        "          record={}\n",
        "          filename = os.path.join(source_path, img_info[\"file_name\"])\n",
        "          # print(filename)\n",
        "          record[\"file_name\"] = filename\n",
        "          record[\"image_id\"] = img_info['id']\n",
        "          record[\"height\"] = img_info['height']\n",
        "          record['width'] = img_info['width']\n",
        "        \n",
        "          box_info = []\n",
        "          \n",
        "          for anno in annotationinfo:\n",
        "            if anno[\"image_id\"] == img_info['id']:\n",
        "              # if (anno['category_id'] <= 3) & (anno['category_id'] > 0):\n",
        "              if (anno['category_id'] == 1) & (anno['category_id'] > 0): # Predict people only\n",
        "                        box = {\n",
        "                        \"bbox\": anno['bbox'],\n",
        "                        'bbox_mode': BoxMode.XYWH_ABS, # Category_id starts from 0 in detectron2\n",
        "                        'category_id': int(anno['category_id']-1)  #we forcibly convert this shit into integer to be able to minus 1. just incase the stuff from the dict is integer\n",
        "                        #computer counts from zero but not hyman. we have to substract one to match the computer #update Jun29: i deleted -1, bcz there is no category 0 \n",
        "                        } #exactly how dictionary looks like\n",
        "                        imagetesthaha = cv2.imread(filename, 0) \n",
        "                        tt = cv2.rectangle(imagetesthaha, anno[\"bbox\"], (255,0,0),2)\n",
        "                        #cv2_imshow(tt) #for printing all boxes in images one by one, will crash\n",
        "                        box_info.append(box)\n",
        "          record[\"annotations\"] = box_info\n",
        "\n",
        "          data_dicts.append(record)\n",
        "    return data_dicts\n",
        "\n",
        "      \n",
        "      \n",
        "    #print(type(jsonfile)) #check the  type of jsonfile. dict or list or stuff\n",
        "\n",
        "\n",
        "\n",
        "#define dataloader for training and testing sets\n",
        "#train_dataloader = dataloader(training_data, batch_size=64, shuffle=True)\n",
        "#test_dataloader = dataloader(test_data, batch_size=64, shuffle=True)\n"
      ],
      "metadata": {
        "id": "aw-C6cO3s7te"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def FLIR_dataset_wrapper(source_path, img_dir, anno_dir):\n",
        "    def wrapper():\n",
        "        return FLIR(source_path, img_dir, anno_dir)\n",
        "    return wrapper"
      ],
      "metadata": {
        "id": "42NjdwA7s84e"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DatasetCatalog.clear() #unregister stuff"
      ],
      "metadata": {
        "id": "-Y2_0J2Ws_ln"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for d in [\"train\", \"val\"]:\n",
        "    DatasetCatalog.register(\"FLIR_THERMAL_\" + d + \"_data\", lambda d=d: FLIR(\"/content/drive/MyDrive/FLIR_THERMAL/train\", \"data\", \"coco.json\")) #changed \"/directry/stuff/\" +d +\"shit\" into this rn\n",
        "    MetadataCatalog.get(\"FLIR_THERMAL_\" + d + \"_data\").set(thing_classes=[\"FLIR_THERMAL\"])\n",
        "FLIR_metadata = MetadataCatalog.get(\"FLIR_THERMAL_train_data\")\n"
      ],
      "metadata": {
        "id": "zy8Vs0-EtBjr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convert_to_coco_json('FLIR_THERMAL_train_data', output_file='content/drive/MyDrive/output/inference/FLIR_Thermal_Train_coco_format.json', allow_cached=False)\n"
      ],
      "metadata": {
        "id": "rJNlhpwmtDIJ",
        "outputId": "6097f00a-cc3b-4171-8ab7-c498592a80c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[08/31 07:01:14 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'FLIR_THERMAL_train_data' to COCO format ...)\n",
            "\u001b[32m[08/31 07:17:05 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
            "\u001b[32m[08/31 07:17:10 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 10742, #annotations: 50478\n",
            "\u001b[32m[08/31 07:17:10 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at 'content/drive/MyDrive/output/inference/FLIR_Thermal_Train_coco_format.json' ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to varify our thing by calling the function\n",
        "dataset_dicts = FLIR(\"/content/drive/MyDrive/FLIR_THERMAL/train\", \"data\", \"coco.json\")\n"
      ],
      "metadata": {
        "id": "XmHoP3sutEwl"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://cloudstor.aarnet.edu.au/plus/s/glqFc13cCoEyHYy/download -O fcos_R_50_1x.pth #download pretrained model"
      ],
      "metadata": {
        "id": "4ISSaapatHR0",
        "outputId": "92a6b03b-ac53-4620-ae32-3d93c452c65d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-31 07:28:37--  https://cloudstor.aarnet.edu.au/plus/s/glqFc13cCoEyHYy/download\n",
            "Resolving cloudstor.aarnet.edu.au (cloudstor.aarnet.edu.au)... 202.158.207.20\n",
            "Connecting to cloudstor.aarnet.edu.au (cloudstor.aarnet.edu.au)|202.158.207.20|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Syntax error in Set-Cookie: 5230042dc1897=giapqbut8sl7jfs3at0ghb1nvi; path=/plus;; Secure at position 53.\n",
            "Syntax error in Set-Cookie: oc_sessionPassphrase=a%2F4AXm%2F8wqYSnyuZ5xnXVdMYTXBdOpJaYIA9hcED%2F5ZniJa8TYAucPnuKeG5sF2f564q7KhdNeSKF2Wg1mRQ1S8wekoZT2qk25k9T4yxCvgmxAqAKT9x8DRI%2FrN9ptXs; expires=Thu, 01-Sep-2022 07:28:38 GMT; Max-Age=86400; path=/plus;; Secure at position 224.\n",
            "Length: 129471951 (123M) [application/octet-stream]\n",
            "Saving to: ‚Äòfcos_R_50_1x.pth‚Äô\n",
            "\n",
            "fcos_R_50_1x.pth    100%[===================>] 123.47M  10.9MB/s    in 13s     \n",
            "\n",
            "2022-08-31 07:28:51 (9.44 MB/s) - ‚Äòfcos_R_50_1x.pth‚Äô saved [129471951/129471951]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAINÔºÅ"
      ],
      "metadata": {
        "id": "FD-qvMnJtL_R"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dQX1dlC8wz3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "before training we have to change the file in  /content/cocoapi/PythonAPI/FCOS/fcos_core/config/paths_catalog.py\n",
        "\n",
        "        \"FLIR_THERMAL_train_data\":{\n",
        "            \"img_dir\": \"/content/drive/MyDrive/FLIR_THERMAL/train/data\",\n",
        "            \"ann_file\": \"/content/drive/MyDrive/FLIR_THERMAL/train/coco.json\"          \n",
        "        },\n",
        "       \"FLIR_THERMAL_val_data\":{\n",
        "            \"img_dir\": \"/content/drive/MyDrive/FLIR_THERMAL/val/data\",\n",
        "            \"ann_file\": \"/content/drive/MyDrive/FLIR_THERMAL/val/coco.json\"          \n",
        "        },\n",
        "add these 2 datasets manually\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "M3XMPdSywzvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.DATASETS.TRAIN = (\"FLIR_THERMAL_train_data\",)\n",
        "cfg.MODEL.RESNETS.DEPTH = 50 #for mvit v2 S we are setting the depth = 101. (F)\n",
        "# cfg.DATASETS.TEST = ('SMALL_FLIR_THERMAL_val_data',)\n",
        "\n",
        "!python -m torch.distributed.launch \\\n",
        "    --nproc_per_node=8 \\\n",
        "    --master_port=$((RANDOM + 10000)) \\\n",
        "    tools/train_net.py \\\n",
        "    --skip-test \\\n",
        "    --config-file /content/cocoapi/PythonAPI/FCOS/fcos/configs/fcos_R_50_FPN_1x.yaml \\\n",
        "    DATALOADER.NUM_WORKERS 2 \\\n",
        "    OUTPUT_DIR /content/drive/MyDrive/fcos_R_50_FPN_1x\n",
        "\n",
        "# cfg.merge_from_file(\"/content/swin/configs/SwinT/faster_rcnn_swint_T_FPN_3x.yaml\")\n",
        "cfg.MODEL.WEIGHTS = \"/content/cocoapi/PythonAPI/FCOS/fcos_R_50_1x.pth\" \n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.SOLVER.IMS_PER_BATCH = 4  # This is the real \"batch size\" commonly known to deep learning people 'changed to 5'\n",
        "cfg.SOLVER.BASE_LR = 0.0001 #SET ALL TO 0.0001\n",
        "cfg.SOLVER.MAX_ITER = 270000    # 270000 for 3x (F)\n",
        "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
        "cfg.SOLVER.WARMUP_FACTOR = 1.0 / 5000\n",
        "cfg.SOLVER.WARMUP_ITERS = 5000\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   # chose 512 for 3x\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (people). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
        "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
        "cfg.MODEL.MASK_ON = False\n",
        "# cfg.MODEL.RESNETS.DEFORM_MODULATED = True\n",
        "cfg.MODEL.BACKBONE.FREEZE_AT = 0\n",
        "cfg.OUTPUT_DIR = \"/content/drive/MyDrive/FCOSTEST\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # load pretrained weights\n",
        "# other_weights = torch.load('/content/swin_tiny_patch4_window7_224_d2.pth')['model']\n",
        "# cfg.self_weight = trainer.model.state_dict()\n",
        "# # for name, param in self_weight.items():\n",
        "# #     if name in other_weights:\n",
        "# #         if other_weights[name].shape == param.shape:\n",
        "# #             self_weight[name] = other_weights[name]\n",
        "# #         else:\n",
        "# #             print(f\"size mismatch at {name}\")\n",
        "# #     else:\n",
        "# #         print(f\"layer {name} does not exist\")\n",
        "# cfg.trainer.model.load_state_dict(self_weight)\n",
        "\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = DefaultTrainer(cfg) \n",
        "trainer.resume_or_load(resume=True)\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "piKw265CtLu0",
        "outputId": "e3191cfe-e5ec-4f67-e624-61bb11cb55a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/bin/python: Error while finding module specification for 'torch.distributed.launch' (ModuleNotFoundError: No module named 'torch')\n",
            "\u001b[32m[08/31 07:36:55 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): ResNet(\n",
            "    (stem): BasicStem(\n",
            "      (conv1): Conv2d(\n",
            "        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "      )\n",
            "    )\n",
            "    (res2): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (res3): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (3): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (res4): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (3): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (4): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (5): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): Res5ROIHeads(\n",
            "    (pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (res5): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=2048, out_features=2, bias=True)\n",
            "      (bbox_pred): Linear(in_features=2048, out_features=4, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    }
  ]
}